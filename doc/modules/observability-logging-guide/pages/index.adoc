:sample-project: jmix-observability-logging-sample

= Observability: Logging

In this guide, you will learn how to set up centralized logging for your Jmix application using OpenTelemetry, Grafana Loki, and Grafana.

[[requirements]]
== Requirements

If you want to implement this guide step by step, you will need the following:

1. xref:ROOT:setup.adoc[Setup Jmix Studio]
2. Download the sample project. You can **download the completed sample project**, which includes all the examples used in this guide. This allows you to explore the finished implementation and experiment with the functionality right away.
* https://github.com/jmix-framework/{sample-project}/archive/refs/heads/main.zip[Download^] and unzip the source repository
* or clone it using git:
`git clone https://github.com/jmix-framework/{sample-project}.git`

Alternatively, you can **start with the base Petclinic project** and follow the step-by-step instructions in this guide to implement the features yourself: https://github.com/jmix-framework/jmix-petclinic-2[Jmix Petclinic] and follow along to add the functionality step-by-step.

[[what-we-are-going-to-build]]
== What We are Going to Build

This guide focuses on setting up centralized logging across two applications: the Jmix Petclinic application and the Jmix Petclinic Portal.

As part of the setup, we also explore how the Petclinic Portal is built and how it interacts with the Petclinic backend using the Jmix REST Data Store.

The main steps covered in this guide are:

- Configuring both applications to send their logs to a centralized logging system.
- Setting up the supporting infrastructure, including the OpenTelemetry Collector, Grafana Loki as the logging database, and Grafana as the visualization UI.
- Configuring the applications to export their logs in a format compatible with the OpenTelemetry Collector.

[[petclinic-portal]]
=== Petclinic Portal

[NOTE]
====
The following section describes the Petclinic Portal application, its connection to the Petclinic backend, and how the integration is set up.

If you are only interested in centralized logging and observability topics, you can skip this section and continue directly with xref:introduction-to-observability[].
====

The Petclinic Portal allows pet owners to log in and view their data, including pets, past and upcoming visits, and contact information for the clinic. This functionality is a typical example of a consumer-facing app that offers self-service capabilities while staying connected to a central backend.

image::petclinic-portal-pet-list-view.png[Petclinic Portal Pet List View, link="_images/petclinic-portal-pet-list-view.png"]

[[petclinic-portal-integration]]
==== Integration with REST Data Store

The Jmix REST Data Store provides an easy way to connect two Jmix applications using a REST API. In this setup, the Petclinic Portal fetches data such as `Pet` and `Visit` entities from the Petclinic backend without persisting or managing the data itself.

By leveraging the REST Data Store, the Petclinic Portal and the Petclinic backend are cleanly separated.

This enables deploying the Portal as an internet-facing application with its own authentication mechanisms, such as OIDC, without exposing the full backend to the internet. Only a minimal, targeted subset of functionality is exported, making it easier to tailor the user experience precisely to the needs of the end users while maintaining a strict separation between core data management and customer-facing operations.

==== Exposing generic REST API in Petclinic

To enable the Petclinic application to expose its data through REST, we first need to add the following dependencies to the `build.gradle` file:

.build.gradle
[source,java,indent=0]
----
include::example$/petclinic/build.gradle[tags=rest-api-dependencies]
----
This will add support for the Jmix Generic REST API and OAuth2 authorization server capabilities to the application.

In order to allow the Petclinic Portal to access the Petclinic backend, we configure an OAuth2 client for the portal in the `application.properties` file of the Petclinic backend.

.application.properties
[source,java,indent=0]
----
include::example$/petclinic/src/main/resources/application.properties[tags=jmix-authorization-server-portal-client]
----

[NOTE]
====
In this configuration, the Petclinic Portal authenticates as a system client using the `client_credentials` flow.

This avoids the need for creating user accounts in the Petclinic, and instead applies data filtering programmatically within the portal application.
====

With these configurations, the Jmix Petclinic application now exposes a REST API protected by OAuth2. Let's now look into how to configure the Portal application to use the Petclinic REST API backend.

==== Connecting Petclinic Portal to the Backend

To enable the Petclinic Portal to connect to the Petclinic backend and access its data, we first need to configure the REST Data Store module in the portal application.

First, add the following dependencies to the `build.gradle` file of the Petclinic Portal application:

.build.gradle
[source,java,indent=0]
----
include::example$/portal/build.gradle[tags=rest-ds-dependencies]
----

Next, we need to configure the connection details to the backend Petclinic application in the `application.properties` file:

.application.properties
[source,java,indent=0]
----
include::example$/portal/src/main/resources/application.properties[tags=jmix-rest-ds-connectivity]
----

This configuration does the following:

- Registers an additional data store named `petclinic` that uses the Jmix REST Data Store (`RestDataStoreDescriptor`).
- Defines the connection URL (`baseUrl`) for accessing the Petclinic backend REST API.
- Configures the OAuth2 `clientId` and `clientSecret` to authenticate the portal application against the backend.

Once the connection to the Petclinic backend is configured, the portal application can interact with entities exposed by the REST API.

We create a Pet Jmix DTO Entity in the portal application that represents the data structure we need from the backend. The DTO entity must be annotated appropriately to link it to the backend system.

.Pet.java
[source,java,indent=0]
----
include::example$/portal/src/main/java/io/jmix/petclinic/portal/entity/Pet.java[tags=start-class;end-class]
----
<1> `@Store(name = "petclinic")` — specifies that the entity belongs to the additional `petclinic` data store.
<2> `@RestDataStoreEntity(remoteName = "petclinic_Pet")` — maps the DTO to the corresponding entity name exposed by the petclinic REST API.

After creating and connecting the DTO entities, we can use them like any other entities within Jmix views.

We define a data loader in the Portal `pet-list-view.xml` to load `Pet` entities. When using the Jmix REST Data Store, the data loader works slightly differently compared to standard database loaders: it uses a JSON-based query format instead of JPQL.

Here’s an example of how the `Pet` entities are loaded for the currently logged-in owner:

.pet-list-view.xml
[source,xml,indent=0]
----
include::example$/portal/src/main/resources/io/jmix/petclinic/portal/view/pet/pet-list-view.xml[tags=loading-pets]
----

For more information on how to define queries and filters when using the Jmix REST Data Store, refer to: xref:rest-ds:index.adoc#using-query-in-view-xml[].

[[petclinic-portal-custom-layout]]
==== Portal Custom Layout

To meet the requirements of a consumer-facing application, the Petclinic Portal uses a custom layout that goes beyond standard Jmix UI components. Cards, color coding, and visual grouping of data are implemented to give users a modern and intuitive experience.

image::petclinic-portal-visit-list-view.png[Petclinic Portal Visit List View, link="_images/petclinic-portal-visit-list-view.png"]

image::petclinic-portal-visit-detail-view.png[Petclinic Portal Visit Detail View, link="_images/petclinic-portal-visit-detail-view.png"]

We use a Fragment to represent each `Pet` entity visually as a card component. Each card displays key information such as the pet’s name, type, birthdate, and offers a button to navigate to the detail view.

.pet-card.xml
[source,xml,indent=0]
----
include::example$/portal/src/main/resources/io/jmix/petclinic/portal/view/pet/pet-card.xml[]
----

The visual appearance of the cards is defined using a small set of custom CSS classes that extend and complement the standard Lumo theme. These styles are organized in a dedicated file under `src/main/frontend/themes/jmix-petclinic-portal/view/pet-card.css`:

.pet-card.css
[source,css,indent=0]
----
include::example$/portal/src/main/frontend/themes/jmix-petclinic-portal/view/pet-card.css[]
----

Cards are dynamically created when the `Pet` data is loaded into the Pet List View by reacting to a `CollectionContainer.CollectionChangeEvent` on the data container.

This event listener allows us to rebuild the card layout each time the set of loaded pets changes.

.PetListView.java (excerpt)
[source,java,indent=0]
----
include::example$/portal/src/main/java/io/jmix/petclinic/portal/view/pet/PetListView.java[tags=init-pet-cards]
----

NOTE: To see how to build such consumer-facing applications with Jmix in more detail, watch the following video:
https://www.youtube.com/watch?v=roBa0Qb8R2E[Building Consumer-Facing Apps with Jmix^]

[[introduction-to-observability]]
=== Introduction to Observability

Observability is the ability to understand the internal state of a system based on the data it produces.

While observability is beneficial for any application, it becomes especially critical in distributed systems and microservice architectures, where system complexity increases and understanding behavior across multiple components becomes significantly more challenging.

In traditional environments, administrators could often still introspect systems at the operating system level to investigate problems. In modern cloud environments, containerized setups, and Kubernetes-based infrastructures, this is no longer possible. Applications are isolated, ephemeral, and distributed across nodes, making direct access for debugging or inspection infeasible.

As a result, the need has emerged to extract telemetry data — logs, metrics, and traces — directly from applications and forward it into specialized observability systems for centralized collection, analysis, and monitoring.

Observability is typically built around three main pillars:

- **Logs**: Structured or unstructured records of events that have occurred within the system.
- **Metrics**: Numerical data that represent measurements over time, such as response times, error rates, or system load.
- **Traces**: Records of the flow of a request as it passes through different parts of the system.

In this guide, we focus primarily on logging. We will see how to use structured logs and centralize logging across multiple applications to improve monitoring, troubleshooting, and overall system understanding.

[[centralized-logging]]
=== Centralized Logging

Centralized logging refers to the practice of collecting log data from multiple applications and systems into a single, centralized location for analysis and monitoring. This approach simplifies troubleshooting, enhances visibility across distributed systems, and enables proactive issue detection.

There are various ways to implement centralized logging. Many cloud providers offer managed logging services, such as AWS CloudWatch, Google Cloud Logging, or Microsoft Azure Monitor, which automatically collect logs from infrastructure and applications. Additionally, there are SaaS-based observability platforms like Datadog, which provide extensive logging, monitoring, and alerting capabilities as a service. For teams that prefer to manage their own infrastructure, self-hosted solutions such as the Elastic Stack (formerly ELK Stack) or Grafana Loki are popular options. These solutions allow full control over data retention, cost management, and system integration.

Despite their differences, centralized logging systems share a common architecture. Typically, one or more components are responsible for receiving log data from applications (collectors or agents), and another component stores and indexes the logs for querying and visualization. Centralized logging significantly improves system observability by enabling cross-application search, building dashboards, and detecting patterns or anomalies across the entire environment.

[[structured-logging]]
=== Structured Logging

Structured logging refers to writing logs in a machine-readable format such as JSON or key-value pairs, rather than plain text messages. This makes it significantly easier for centralized logging systems to parse, index, and query logs efficiently.

With structured logs, fields like `userId`, `petId`, or `errorType` can be used directly in queries, enabling fast and precise troubleshooting. It also supports advanced use cases such as automated detection and masking of sensitive information (PII), building dynamic dashboards, and correlating events across distributed systems.

Here’s an example of a structured log entry in JSON format:

[source,json]
----
{
  "timestamp": "2025-04-26T08:45:30.123Z",
  "level": "ERROR",
  "service": "petclinic-portal",
  "errorType": "ValidationError",
  "message": "Pet name must not be empty",
  "attributes": {
    "userId": "8fa85f64-5717-4562-b3fc-2c963f66afa6",
    "petId": "5e8b6c45-0c12-4f0f-bc47-1a6a5d2cf08d"
  }
}
----

In contrast, a traditional log entry using a default Logback console appender might look like this:

[source,text]
----
2025-04-26 08:45:30 ERROR  [http-nio-8080-exec-7] io.jmix.petclinic.portal.view.pet.PetListView - Pet name must not be empty for Pet: 5e8b6c45
----

In the unstructured format, important details like the `userId` are missing, and the `petId` is embedded inside the text, making it difficult for automated systems to extract and use this information reliably.

To fully benefit from centralized logging, applications should produce structured logs natively. Structured data makes it possible to query specific fields and build rich, user-specific dashboards across distributed systems.

[[grafana-loki]]
=== Grafana Loki and Grafana UI

In this guide, we use Grafana Loki as the centralized backend for storing and querying application logs, and Grafana as the user interface for visualization.

Unlike the Elastic Stack (ELK), which indexes the full content of log messages, Loki only indexes a small set of labels (like `app`, `env`, or `service`) and stores the actual log content separately. This design makes Loki much more efficient in terms of storage and memory usage, while still enabling powerful filtering and search capabilities for common queries.

We chose Loki because it integrates seamlessly into the broader Grafana observability stack, alongside Tempo for distributed tracing and Prometheus for metrics, offering a consistent and unified monitoring experience.

We also use Grafana as a unified observability interface where all telemetry data — logs, metrics, and traces — can be visualized and explored in one place.

Initially, we connect it to Loki to collect and analyze application logs. In follow-up guides, we will extend the setup to include metrics from Prometheus and distributed traces from Tempo, all integrated into Grafana for a seamless observability experience.

==== Setting up Grafana Loki and Grafana using Docker

We run Loki and Grafana locally via Docker for centralized logging and visualization.

A minimal setup for running both Loki and Grafana using Docker is provided below.

.docker-compose.yaml
[source,yaml,indent=0]
----
include::example$/docker/docker-compose.yaml[tags=loki]
----

We also provision Grafana with a data source configuration that connects it automatically to Loki:

.grafana-datasources.yaml
[source,yaml,indent=0]
----
include::example$/docker/grafana-datasources.yaml[tags=start;loki-only]
----

To start the infrastructure, simply run the following command from the project root:

[source,shell]
----
docker compose -f docker/docker-compose.yaml up -d
----

With Grafana and Loki running, we can now start forwarding logs from our applications into the centralized logging system.

To do this, we need an intermediate component that receives the logs and forwards them to Loki: the OpenTelemetry Collector.

[[open-telemetry]]
=== OpenTelemetry

OpenTelemetry is an open-source project that defines standards and components for collecting, transmitting, and processing telemetry data such as logs, metrics, and traces.

In this guide, OpenTelemetry is mainly relevant as the mechanism we use to transport logs from the applications to the centralized backend. We use the **OpenTelemetry Collector** as an intermediary: it receives telemetry data from the applications and forwards it to Grafana Loki. This approach decouples the applications from the backend and gives flexibility to switch or extend targets easily.

Communication happens via the **OpenTelemetry Protocol (OTLP)**, a standardized and vendor-neutral protocol for transmitting logs, metrics, and traces. OTLP is widely supported by many observability platforms, both self-hosted and cloud-based, allowing us to remain flexible and independent of a specific backend technology.

==== OpenTelemetry Collector Setup

We use the OpenTelemetry Collector to receive logs via OTLP and forward them to Grafana Loki.

Thanks to the standardized OTLP format, the setup remains flexible and can easily be extended to send telemetry data to other observability backends if needed.

We run the OpenTelemetry Collector as a Docker container. The `docker-compose.yaml` contains the necessary definition:

.docker-compose.yaml
[source,yaml,indent=0]
----
include::example$/docker/docker-compose.yaml[tags=otel-collector]
----

The OpenTelemetry Collector is configured using a YAML file (`otelcol-config.yaml`). We configure it to receive logs over OTLP (on port `4318`), process them in batches, and export them to Grafana Loki.

.otelcol-config.yaml
[source,yaml,indent=0]
----
include::example$/docker/otelcol-config.yaml[]
----

[[spring-boot-actuator-open-telemetry-integration]]
=== Spring Boot Actuator and OpenTelemetry Integration

We use Spring Boot Actuator as the main way to expose operational data from our applications. Actuator provides a set of ready-made endpoints like `/health`, `/metrics`, and `/loggers`, which can be used for monitoring and management purposes — though in this guide, our focus is specifically on logging.

More importantly, Actuator integrates with https://micrometer.io[Micrometer], a metrics and observation library that enables applications to export telemetry data such as metrics and traces. This integration forms the basis for structured telemetry collection in Spring Boot applications.

For log collection, we extend Actuator's capabilities by wiring the logging system to the OpenTelemetry Collector using the OpenTelemetry Logback Appender. This allows us to export structured logs from the application in the OpenTelemetry Protocol (OTLP) format, ready to be picked up by the centralized collector.

In this part of the guide, we focus on configuring structured logging with OpenTelemetry. In later parts, we will build on the same foundation to add metrics and distributed tracing.

[[spring-boot-actuator-open-telemetry-integration]]
=== Spring Boot Actuator and Application Setup

We configure our applications to export structured logs directly to the OpenTelemetry Collector using Spring Boot Actuator and Micrometer.

==== Dependencies

First, we add the required dependencies to the `build.gradle`:

.build.gradle
[source,gradle,indent=0]
----
include::example$/portal/build.gradle[tags=actuator-logging-deps]
----

Next, we define the OTLP logging endpoint in the application's `application.properties`:

.application.properties
[source,properties,indent=0]
----
include::example$/portal/src/main/resources/application.properties[tags=logging-export]
----

This configuration points the log output to the OpenTelemetry Collector running locally.


Additionally we need to create the logging configuration (`logback-spring.xml`) to forward log events both to the console and to OpenTelemetry:

.logback-spring.xml
[source,xml,indent=0]
----
include::example$/portal/src/main/resources/logback-spring.xml[]
----

Finally, we initialize the OpenTelemetry Logback Appender at application startup to connect it properly with the OpenTelemetry SDK:

.OpenTelemetryAppenderInitializer.java
[source,java,indent=0]
----
include::example$/portal/src/main/java/io/jmix/petclinic/portal/config/OpenTelemetryAppenderInitializer.java[]
----

With this setup in place, all application logs are structured, enriched with contextual metadata, and sent directly to the OpenTelemetry Collector via OTLP.

[[summary]]
== Summary

Two - three paragraphs of summary text

[[further-information]]
=== Further Information

* xref:data-access:entity-events.adoc[]
